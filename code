Train model: 

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error
import pickle
import json

# Load dataset
df = pd.read_csv('/content/Salary Data.csv')

# Step 1: Handle missing values
df = df.dropna(subset=['Salary'])
df['Years of Experience'] = df['Years of Experience'].fillna(df['Years of Experience'].median())
df['Age'] = df['Age'].fillna(df['Age'].median())
df['Job Title'] = df['Job Title'].fillna(df['Job Title'].mode()[0])
df['Education Level'] = df['Education Level'].fillna(df['Education Level'].mode()[0])

# Step 2: Features and target
X = df[['Job Title', 'Years of Experience', 'Education Level', 'Age']]
y = df['Salary']

# Step 3: Preprocessing pipeline
numeric_features = ['Years of Experience', 'Age']
categorical_features = ['Job Title', 'Education Level']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ]
)

# Combine preprocessing with Linear Regression
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('model', LinearRegression())
])

# Step 4: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Train model
pipeline.fit(X_train, y_train)

# Evaluate model
y_pred = pipeline.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.2f}")

# Step 6: Save trained pipeline
with open('linear_model.pkl', 'wb') as file:
    pickle.dump(pipeline, file)

# Download trained model
from google.colab import files
files.download('linear_model.pkl')

# Step 7: Save dropdown mappings for Streamlit UI
job_titles = sorted(list(df['Job Title'].unique()))
education_levels = sorted(list(df['Education Level'].unique()))

# Save them to mappings.json
with open('mappings.json', 'w') as file:
    json.dump({'job_titles': job_titles, 'education_levels': education_levels}, file)

# Download mappings.json for use in VS Code
from google.colab import files
files.download('mappings.json')



Interface:

import streamlit as st
import numpy as np
import pandas as pd
import pickle
import json

# Load trained pipeline
with open('linear_model.pkl', 'rb') as file:
    pipeline = pickle.load(file)

# Load dropdown options (sorted order already applied in Colab)
with open('mappings.json', 'r') as file:
    mappings = json.load(file)

job_titles = mappings['job_titles']
education_levels = mappings['education_levels']

# Streamlit App
st.title("Employee Salary Prediction")


st.write("This app predicts employee salary based on Job Title, Years of Experience, Education Level, and Age.")

# User Inputs
job_title = st.selectbox("Select Job Title", job_titles)
experience_years = st.number_input("Enter Years of Experience", min_value=0, max_value=50, value=5)
education_level = st.selectbox("Select Education Level", education_levels)
age = st.number_input("Enter Age", min_value=18, max_value=100, value=30)

# Predict Salary
if st.button("Predict Salary"):
    input_data = pd.DataFrame([[job_title, experience_years, education_level, age]],
                              columns=['Job Title', 'Years of Experience', 'Education Level', 'Age'])

    predicted_salary = pipeline.predict(input_data)[0]
    st.success(f'Predicted Salary: ${predicted_salary:,.2f}')
